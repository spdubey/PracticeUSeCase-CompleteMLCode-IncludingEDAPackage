{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installed packages\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "import numpy as np\n",
    "# silencing the warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "'''\n",
    "!pip install nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "!pip install numba\n",
    "'''\n",
    "\n",
    "# created packages\n",
    "import nlp_ops as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    '''\n",
    "    reads the train and test data\n",
    "    '''\n",
    "    train_data = pd.read_csv(\"Train.csv\")\n",
    "    test_data = pd.read_excel(\"Test.xlsx\")\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_city(row, city_str):\n",
    "    '''\n",
    "    This function cleans the city present in job desig column\n",
    "    '''\n",
    "    row_list =  [each_word.lower().strip('.').strip().strip('.') for each_word in row.split()]\n",
    "    for elem in row_list:\n",
    "        if elem in city_str:\n",
    "            row_list.remove(elem)\n",
    "    return ' '.join(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(stitched_data):\n",
    "    '''\n",
    "    this function does data cleaning\n",
    "    '''\n",
    "    print(\"Dropping job_type column\")\n",
    "    stitched_data.drop(columns = ['job_type'], inplace = True)\n",
    "    # Fill missing value, replace '...' from text columns, cleaning location columns\n",
    "    for col in stitched_data.columns:\n",
    "        if stitched_data.dtypes[col] == 'object':\n",
    "            stitched_data[col] = stitched_data[col].str.lower()\n",
    "            stitched_data[col] = stitched_data[col].str.replace('\\(.*\\)', '')\n",
    "            stitched_data[col] = stitched_data[col].str.replace('\\.\\.\\.', '')\n",
    "            stitched_data[col] = stitched_data[col].fillna(stitched_data[col].mode()[0])\n",
    "        elif stitched_data.dtypes[col] == 'float64':\n",
    "            stitched_data[col] = stitched_data[col].fillna(stitched_data[col].mean())\n",
    "\n",
    "    # remove city name from columns 'job_description', 'job_desig'\n",
    "    city_name = pd.read_csv('india_city_list.csv')\n",
    "    city_name = city_name.India_city_list.str.lower().str.strip().replace('.','')\n",
    "    city_str =' '.join(city_name.to_list())\n",
    "    stitched_data['job_desig'] = stitched_data['job_desig'].apply(lambda row :remove_city(row, city_str))\n",
    "    stitched_data['job_description'] = stitched_data['job_description'].apply(lambda row :remove_city(row, city_str))\n",
    "    stitched_data['location_type'] = ['tier_one' if x in ['mumbai', 'bengaluru', 'delhi','delhi ncr',\n",
    "                                              'chennai', 'hyderabad','gurgaon', \n",
    "                                              'gurugram', 'kolkata'] else 'tier_two' for x in stitched_data['location']] \n",
    "    \n",
    "    stitched_data.drop(columns = ['location'], inplace = True)\n",
    "    for col in stitched_data.columns:\n",
    "        if stitched_data.dtypes[col] == 'object':\n",
    "            stitched_data[col] = stitched_data[col].fillna(stitched_data[col].mode()[0])\n",
    "        elif stitched_data.dtypes[col] == 'float64':\n",
    "            stitched_data[col] = stitched_data[col].fillna(stitched_data[col].mean())\n",
    "    \n",
    "    return stitched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EDA(stitched_data):\n",
    "    '''\n",
    "    creates the EDA report using pyEDA package(self created)\n",
    "    '''\n",
    "    from pyEDA.pyEDA.data_profile import profile\n",
    "    eda_result = profile(stitched_data, get_summary=True,\n",
    "                get_data_type=True,\n",
    "                get_skewness={'df':True, 'plot' :False},\n",
    "                get_kurtosis=None,\n",
    "                get_missing={'df':True, 'plot' :False},\n",
    "                get_missing_visual={'df':True, 'plot' :False},\n",
    "                get_distinct={'df':True, 'plot' :True},\n",
    "                get_categorical_count={'df':True, 'plot' :False},\n",
    "                get_numerical_dist_plot={'df':True, 'plot' :False},\n",
    "                get_numeric_box_plot={'df':True, 'plot' :False},\n",
    "                get_row_wise_missing={'df':True, 'plot' :False},\n",
    "                get_correlation={'df':True, 'plot' :False},\n",
    "                generate_html_report=True)\n",
    "    return eda_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_col(word2vec_model, data):\n",
    "    '''\n",
    "    this function creates a numerical vector of the preprocessing include :\n",
    "    filter_tag_pos,  lemmatize_word, stop-words, punctuation removal, number removal\n",
    "    '''\n",
    "    print(\"inside clean data\")\n",
    "    # cleaning Data Text columns - 'job_description', 'job_desig', 'key_skills'\n",
    "    nlp_cols = ['job_description', 'job_desig', 'key_skills']    \n",
    "    cleaned_text = nlp.text_clean(word2vec_model, data, nlp_cols)\n",
    "    for col in nlp_cols:\n",
    "        cleaned_text[col] = cleaned_text[col].apply(lambda x : abs(np.mean(x)) *10000)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(cleaned_data):\n",
    "    '''\n",
    "    this function does data preparation including dummy data creation and feature engineering\n",
    "    '''\n",
    "    cleaned_data[['exp_lower', 'exp_upper']] = cleaned_data.experience.str.split('-', expand=True)\n",
    "    cleaned_data['exp_upper'] = cleaned_data.exp_upper.str.split(' ', expand=True)[0]\n",
    "    cleaned_data.drop(columns = ['experience'], inplace = True)\n",
    "    # get dummies\n",
    "    cat_vars = ['location_type']\n",
    "    for var in cat_vars:\n",
    "            cat_list='var'+'_'+var\n",
    "            cat_list = pd.get_dummies(cleaned_data[var], prefix=var)\n",
    "            cleaned_data = cleaned_data.join(cat_list)\n",
    "    cleaned_data.drop(columns =['location_type','index'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_train_test(train_data, test_data):\n",
    "    test_data.drop(columns = [clm for clm in test_data.columns if clm not in train_data.columns], inplace = True)\n",
    "    target = train_data['salary']\n",
    "    train_data.drop(columns = ['salary'], inplace=True)\n",
    "    ind = len(train_data)\n",
    "    stitched_data = train_data.append(test_data).reset_index()\n",
    "    return stitched_data, target, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_feat_imp(x, y):\n",
    "    '''\n",
    "    calculate feature importance\n",
    "    '''\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    sel = SelectFromModel(RandomForestRegressor(n_estimators = 100))\n",
    "    sel.fit(x, y)\n",
    "    selected_feat= x.columns[(sel.get_support())].tolist()\n",
    "    selected_feat.append('key_skills')\n",
    "    return selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_regressor(x_train, y_train, x_test):\n",
    "    '''\n",
    "    model building\n",
    "    '''\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    test_data_cpy = x_test.copy()\n",
    "    feat = x_train.copy()\n",
    "    target = y_train['salary_final']\n",
    "    X,x,Y,y = train_test_split(feat,target,random_state=119)\n",
    "    print(len(X),len(x),len(Y),len(y))\n",
    "    regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "    regressor.fit(x, y)\n",
    "    y_pred = regressor.predict(x)\n",
    "    \n",
    "    # Checking RMSE on test set\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from math import sqrt\n",
    "    rms = sqrt(mean_squared_error(y, y_pred))\n",
    "    print('RMSE of RF regressor on test set: {:.2f}'.format(rms))\n",
    "    \n",
    "    # training on complete train set\n",
    "    regressor = RandomForestRegressor(n_estimators = 100, random_state = 0) \n",
    "    regressor.fit(feat,target)\n",
    "    # predicting on test data\n",
    "    y_test_pred = regressor.predict(x_test.drop(columns = ['salary_final']))\n",
    "    test_data_cpy['salary'] = y_test_pred\n",
    "    test_data_cpy['salary'].to_csv(\"submission_rfr.csv\", index = False)  \n",
    "    print(\"RF Model Done\")\n",
    "    return test_data_cpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Data\n",
      "Data Stitched\n",
      "Dropping job_type column\n",
      "Data Cleansed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4097: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:196: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features importance is calculated using random forest and they are :  ['company_name_encoded', 'exp_upper', 'key_skills']\n",
      "14251 4751 14251 4751\n",
      "RMSE of RF regressor on test set: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Model Done\n",
      "14251 4751 14251 4751\n",
      "RMSE of RF regressor on test set: 0.31\n",
      "RF Model Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# reading in data\n",
    "train_data, test_data = read_data()\n",
    "print(\"Read Data\")\n",
    "stitched_data, target, ind = stitch_train_test(train_data, test_data)\n",
    "print(\"Data Stitched\")\n",
    "\n",
    "# creating visualization and EDA report (Note :  this is a self created package, hence commented this)\n",
    "#eda_result = EDA(stitched_data.drop(columns = ['index']))\n",
    "\n",
    "# cleaning the data\n",
    "cleaned_data = clean_data(stitched_data)\n",
    "\n",
    "# preparing the data\n",
    "cleaned_data = data_prep(cleaned_data)\n",
    "\n",
    "# preparing text column\n",
    "#word2vec_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "#cleansed_text_data = prepare_text_col(word2vec_model, cleaned_data)\n",
    "print(\"Data Cleansed\")\n",
    "\n",
    "\n",
    "#cleansed_text_data.to_csv('cleaned_text_data.csv', index = False)\n",
    "cleansed_text_data = pd.read_csv('cleaned_text_data.csv')\n",
    "\n",
    "# filling na got from word2vec processing , as all the words are not present in googles's pretrained model \n",
    "cleansed_text_data = cleansed_text_data.fillna(cleansed_text_data.min())\n",
    "\n",
    "# making a copy of cleaned_data\n",
    "#cleansed_text_data_cpy = cleansed_text_data.copy()\n",
    "\n",
    "# creating traina nd test data from stitched data\n",
    "train_data = cleansed_text_data[:ind]\n",
    "test_data = cleansed_text_data[ind:]\n",
    "train_data['salary'] = target\n",
    "train_data[['salary_low', 'salary_upp']] = train_data.salary.str.split('to', expand=True)\n",
    "train_data['salary_final'] = (train_data['salary_low'].astype(int) + train_data['salary_upp'].astype(int)) / 2\n",
    "train_data.drop(columns =['salary', 'salary_low','salary_upp'], inplace = True)\n",
    "test_data['salary_final'] = 0\n",
    "\n",
    "# fetching all the column names\n",
    "col = train_data.columns.tolist()\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_data = sc.fit_transform(train_data)\n",
    "test_data = sc.transform(test_data)\n",
    "\n",
    "# putting the scaled(numpy array) back into pandas data frame\n",
    "train_data = pd.DataFrame(train_data, columns = col)\n",
    "test_data = pd.DataFrame(test_data, columns = col)\n",
    "\n",
    "# creating x_train, y_train and x_test\n",
    "x_train = train_data.drop(columns=['salary_final'])\n",
    "y_train = pd.DataFrame(train_data['salary_final'], columns=['salary_final'])\n",
    "x_test = test_data\n",
    "\n",
    "# with importance\n",
    "imp_feat = find_feat_imp(x_train, y_train)\n",
    "print(\"The features importance is calculated using random forest and they are : \", imp_feat)\n",
    "\n",
    "# without feature importance fitting model\n",
    "test_data_result_without_feat_imp = RF_regressor(x_train, y_train, x_test)\n",
    "\n",
    "# with feature importance fitting model\n",
    "x_train = train_data.drop(columns=['salary_final'])[['company_name_encoded', 'exp_upper','key_skills']]\n",
    "y_train = pd.DataFrame(train_data['salary_final'], columns=['salary_final'])\n",
    "x_test = test_data[['salary_final','company_name_encoded', 'exp_upper','key_skills']]\n",
    "test_data_result_with_feat_imp = RF_regressor(x_train, y_train, x_test)\n",
    "\n",
    "# writing the result back\n",
    "test_data['salary_final'] = test_data_result_with_feat_imp['salary']\n",
    "final_test_test = pd.DataFrame(sc.inverse_transform(test_data), columns = col)\n",
    "\n",
    "final_test_test.to_csv(\"basic_rfr.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = read_data()\n",
    "test_data['final'] = final_test_test['salary_final']\n",
    "test_data.to_csv(\"result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
